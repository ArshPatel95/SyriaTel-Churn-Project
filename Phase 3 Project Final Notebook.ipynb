{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyriaTel Customer Churn Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display= 'diagram')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('/Users/Arsh/Downloads/bigml_59c28831336c6604c800002a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "df = deepcopy(df_original)\n",
    "# Keeping original dataset separate in case I need to come back to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# I'm going to guess that there is no meaningful correlation between phone number and other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# Thankfully most columns are numerical and do not need to be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "# There are no NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.state.value_counts()\n",
    "# Does not seem to be important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area code'].value_counts()\n",
    "# Should be seen as a categorical column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['international plan'].value_counts()\n",
    "# Binary column - can be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['voice mail plan'].value_counts()\n",
    "# Binary column - can be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_num = df['churn'].value_counts()\n",
    "churn_num\n",
    "# Boolean column - does not need to be converted - also important- vry high class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Customer Churn Numbers\")\n",
    "plt.ylabel(\"Number\")\n",
    "churn_num.plot.bar()\n",
    "# Class imbalance visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "sns.heatmap(df.corr().abs().loc[['churn'],:], annot = True)\n",
    "# Not strong correlation between churn and other columns, closest thing is customer service calls, and daytime charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, corner = True)\n",
    "# Again no strong linear relationship between any variables that are visible from the pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"churn\"], y=df[\"customer service calls\"]).set(title='Churn and Customer Service Calls')\n",
    "# Clear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( x=df[\"churn\"], y=df[\"total day charge\"]).set(title='Churn and Total Day Charge')\n",
    "# Clear relationship - but less linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the different costs for time of day, I suspect as day cost has higher correlation to churn, it is more expensive\n",
    "day_cost = df['total day charge'].sum() / df['total day minutes'].sum()\n",
    "eve_cost = df['total eve charge'].sum() / df['total eve minutes'].sum()\n",
    "night_cost = df['total night charge'].sum() / df['total night minutes'].sum()\n",
    "print(day_cost)\n",
    "print(eve_cost)\n",
    "print(night_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_info1 = {'Day Charge': 0.17000300739130672, 'Eve Charge': 0.0850010487148578, 'Night Charge': 0.04500041448440008}\n",
    "cost_info2 = pd.DataFrame.from_dict(cost_info1, orient='index')\n",
    "cost_info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_info2.plot.bar()\n",
    "plt.suptitle(\"SyriaTel Charges by Time of Day\")\n",
    "plt.ylabel(\"Cost (in cents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This baseline will just use the numerical columns provided. Encoding the nominal columns, such as state and area code will be done later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df.drop(columns = ['state', 'area code', 'phone number', 'international plan', 'voice mail plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df_base['churn']\n",
    "X1 = df_base.drop('churn', axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.30, random_state=20)\n",
    "# First test train split on this df, which has no categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('std_scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(random_state=15))]\n",
    "\n",
    "pipeline1 = Pipeline(steps)\n",
    "\n",
    "\n",
    "# Train the pipeline (tranformations & predictor)\n",
    "pipeline1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict using the pipeline (includes the transfomers & trained predictor)\n",
    "predicted1 = pipeline1.predict(X_test1)\n",
    "predicted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test1, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipeline1, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah. This makes sense, because of class imbalance, the model has trouble predicting True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to do some data wrangling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will convert all my object columns into numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['international plan'] == 'no', 'international_plan'] = 0\n",
    "df.loc[df['international plan'] == 'yes', 'international_plan'] = 1\n",
    "df['international_plan'] = df['international_plan'].astype(int)\n",
    "df.loc[df['voice mail plan'] == 'no', 'voice_mail_plan'] = 0\n",
    "df.loc[df['voice mail plan'] == 'yes', 'voice_mail_plan'] = 1\n",
    "df['voice_mail_plan'] = df['voice_mail_plan'].astype(int)\n",
    "df.loc[df['churn'] == False, 'churn_num'] = 0\n",
    "df.loc[df['churn'] == True, 'churn_num'] = 1\n",
    "df['churn_num'] = df['churn_num'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the converted columns can be removed. \n",
    "df.drop(columns = ['phone number', 'international plan', 'voice mail plan', 'churn'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# This is misleading, technically area code is a nominal category even though it has integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area code'] = df['area code'].astype(object) # Converting this column to an object so it can be run through a pipeline for nominal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area code'].dtypes #Just checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split on fixed df, also made random state number = number of rows\n",
    "y = df['churn_num']\n",
    "X = df.drop('churn_num', axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Am one-hot enoding all categorical columns, the others were binary so they were coverted to numerical ones\n",
    "numeric_pipeline = Pipeline([('numnorm', StandardScaler())])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('onehotenc', OneHotEncoder(sparse = False, drop = 'first')), \n",
    "    ('onehotnorm', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(['int', 'float']).columns\n",
    "ct = ColumnTransformer([(\"nominalpipe\", nominal_pipeline, ['area code','state']),\n",
    "     (\"numpipe\", numeric_pipeline, num_cols)])\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(ct.fit_transform(X_train)).head()\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = pd.DataFrame(ct.transform(X_test)).head()\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('preprocess', ct),\n",
    "                      ('model',\n",
    "                       RandomForestClassifier(random_state=25))])\n",
    "pipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_scaled.columns) #Seeing the number of dummy columns created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much better than I expected, though the Random Forest model is having trouble prediciting True or 1 values in the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "Hypertuning the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {'model__n_estimators': [20, 30, 40, 50, 100], \n",
    "             'model__min_samples_leaf': [1, 3, 5], \n",
    "             'model__max_depth': [4, 6, 8, 10, 12], \n",
    "             'model__min_samples_split': [1, 2, 5, 10, 12]} \n",
    "rf_cv = GridSearchCV(estimator = pipe2, param_grid = rf_parameters, cv = 5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = rf_cv.best_estimator_\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_y_pred = tuned_model.predict(X_test)\n",
    "print(classification_report(y_test,tuned_y_pred))\n",
    "# How is this worse than the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = tuned_model['model'].feature_importances_\n",
    "\n",
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X_test_scaled.columns).sort_values(\n",
    "    ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_series.head()\n",
    "# This is unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (20,20)\n",
    "feat_imp_series.plot(kind = 'bar')\n",
    "# This is awful AND unreadable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "Perhaps using SMOTE will help with the class imbalance in the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = RandomForestClassifier(max_depth=12, n_estimators=40, random_state=25)\n",
    "over = SMOTE(sampling_strategy=0.25)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('preprocess', ct), ('over', over), ('under', under), ('model', tuned_model)]\n",
    "smote_pipeline = Pipeline(steps=steps)\n",
    "smote_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipeline.fit(X_train, y_train);\n",
    "smote_y_pred = smote_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, smote_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(smote_pipeline, X_test, y_test)\n",
    "# Much better, though I did sacrifice some precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new idea\n",
    "Testing an idea that Categorical Features have little predictive effect on customer churn. So I will rerun randomforest model again from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = deepcopy(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning everthing again to maintain continuity\n",
    "df2.drop(columns=['state', 'area code', 'phone number'], inplace = True)\n",
    "df2.loc[df2['international plan'] == 'no', 'international_plan'] = 0\n",
    "df2.loc[df2['international plan'] == 'yes', 'international_plan'] = 1\n",
    "df2['international_plan'] = df2['international_plan'].astype(int)\n",
    "df2.loc[df2['voice mail plan'] == 'no', 'voice_mail_plan'] = 0\n",
    "df2.loc[df2['voice mail plan'] == 'yes', 'voice_mail_plan'] = 1\n",
    "df2['voice_mail_plan'] = df2['voice_mail_plan'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['international plan', 'voice mail plan'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes\n",
    "# Back to where we started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Random Forest Model - No Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = df2['churn']\n",
    "X2 = df2.drop('churn', axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, stratify = y2, test_size=0.30, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('std_scaler', StandardScaler()),\n",
    "        ('new_base', RandomForestClassifier(random_state=20))]\n",
    "\n",
    "new_base = Pipeline(steps)\n",
    "\n",
    "\n",
    "new_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Predict using the pipeline (includes the transfomers & trained predictor)\n",
    "new_y_pred = new_base.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test2, new_y_pred))\n",
    "# This is so much better ... and I did not even tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(new_base, X_test2, y_test2)\n",
    "# Again so much better for a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parameters = {'new_base__n_estimators': [50, 100, 150, 200, 250], \n",
    "             'new_base__min_samples_leaf': [1, 3, 5, 9], \n",
    "             'new_base__max_features': [4, 5, 6, 8]} \n",
    "rf_cv2 = GridSearchCV(estimator = new_base, param_grid = new_parameters, cv = 5)\n",
    "rf_cv2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = rf_cv2.best_estimator_\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Hypertuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model.fit(X_train2, y_train2)\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y_pred = best_rf_model.predict(X_test2)\n",
    "print(classification_report(y_test2, final_y_pred ))\n",
    "# Slightly better but still better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(best_rf_model, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = best_rf_model['new_base'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X_train2.columns).sort_values(\n",
    "    ascending = False)\n",
    "feat_imp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_series.plot(kind = 'barh')\n",
    "# Validates the correlation heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just trying this out...not great, but I still wanted to see if it worked\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(max_features='sqrt',\n",
    "                         max_samples=0.5,\n",
    "                         bootstrap=True,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_etc_pred = etc.predict(X_test2)\n",
    "print(classification_report(y_test2, y_etc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(etc, X_test2, y_test2)\n",
    "# Not very good at predicting true positives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
